{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "import pyflux as pf\n",
    "import csv \n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "splitDataPath = '../dataProcessing/splitData/splitData.csv'\n",
    "testDataPath = '../dataProcessing/splitData/testData.csv'\n",
    "testWeatherPath = '../dataSets/testing_phase1/weather (table 7)_test1.csv'\n",
    "table3 = '../dataSets/training/links (table 3).csv'\n",
    "table4 = '../dataSets/training/routes (table 4).csv'\n",
    "table7 = '../dataProcessing/splitData/weather.csv'\n",
    "arimaPicturePath = '../dataProcessing/arimaPicture/'\n",
    "\n",
    "def getData(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def regularTime(s):\n",
    "    time = datetime.strptime(s,\"%Y-%m-%d %H:%M:%S\")\n",
    "    minute = time.minute\n",
    "    time = time.replace(minute = (minute/20)*20,second = 0)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def splitDataByLane(data,routes):\n",
    "#     label = ['intersection_id','tollgate_id','lane_id','starting_time','time_window','week','pressure','sea_pressure','wind_direction','wind_speed','temperature','rel_humidity','precipitation','travel_lane','travel_velocity','travel_length']\n",
    "    label = ['lane_id','time','pressure','sea_pressure','wind_direction','wind_speed','temperature','rel_humidity','precipitation','travel_velocity']\n",
    "    dataSet = data.copy()\n",
    "    dataSet['travel_velocity'] = dataSet['travel_velocity'].apply(lambda x: np.array(x.split(';')).astype(float))\n",
    "    dataSet['travel_lane'] = dataSet['travel_lane'].apply(lambda x: np.array(x.split(';')).astype(float))\n",
    "    dataSet['travel_length'] = dataSet['travel_length'].apply(lambda x: np.array(x.split(';')).astype(float))\n",
    "    dataSet['travel_seq'] = dataSet['travel_seq'].apply(lambda x: x.split(';'))\n",
    "    dataSet['starting_time'] = dataSet['starting_time'].apply(regularTime)\n",
    "    dataSet.fillna(-1)\n",
    "    \n",
    "    dataSet.drop(['vehicle_id','total_velocity','total_length'],axis = 1,inplace = True)\n",
    "    \n",
    "    \n",
    "    weather = []\n",
    "    weaTmp = dataSet[['starting_time','pressure','sea_pressure','wind_direction','wind_speed','temperature','rel_humidity','precipitation']]\n",
    "    for name,group in weaTmp.groupby(['starting_time']):\n",
    "        temp = []\n",
    "        temp.extend(group.values[0].tolist())\n",
    "        weather.append(temp)\n",
    "    wLabel = ['time','pressure','sea_pressure','wind_direction','wind_speed','temperature','rel_humidity','precipitation']\n",
    "    weather = pd.DataFrame(weather,columns = wLabel)\n",
    "    \n",
    "    print '==========================='\n",
    "    print 'weather data is'\n",
    "    print weather.info()\n",
    "    \n",
    "    result = pd.concat(list(dataSet['travel_seq'].apply(lambda x: pd.DataFrame(x,columns=['lane_id']))))\n",
    "    result['time'] = result['lane_id'].apply(lambda x: x.split('#')[1])\n",
    "    result['time'] = result['time'].apply(regularTime)\n",
    "    result['lane_id'] = result['lane_id'].apply(lambda x: x.split('#')[0])\n",
    "    result['travel_velocity'] = pd.concat(list(dataSet['travel_velocity'].apply(lambda x: pd.DataFrame(x))))\n",
    "    result = pd.merge(result,weather,how = 'left',on = ['time'])\n",
    "    \n",
    "    result['time'] = result['time'].apply(pd.to_datetime)\n",
    "    result.set_index('time',inplace = True)\n",
    "    \n",
    "    print '==========================='\n",
    "    print 'begain to split'\n",
    "    print result.info()\n",
    "    \n",
    "    dataByLink = {}\n",
    "    \n",
    "    for intersection in routes.keys():\n",
    "        for tollgate in routes[intersection].keys():\n",
    "            for lane in routes[intersection][tollgate]:\n",
    "                temp = result[:][result['lane_id'] == lane]\n",
    "                dataByLink[lane] = temp.drop(['lane_id'],axis = 1)\n",
    "#                 print '==========='\n",
    "#                 print lane\n",
    "#                 print dataByLink[lane].info()\n",
    "    \n",
    "    \n",
    "    return dataByLink\n",
    "\n",
    "def handleWeaInflu(data,isTest = False):\n",
    "    label = ['travel_velocity']\n",
    "    # some day (9-28,10-10) lack the information of weather\n",
    "    handleData = data.copy()\n",
    "    \n",
    "    handleData = handleData['travel_velocity'].to_frame()\n",
    "    \n",
    "    # ga\n",
    "    if not isTest:\n",
    "        time=pd.DataFrame(pd.date_range(start = '20160719000000',end = '20161017234000',freq = '20min'),columns=['time'])\n",
    "        result = pd.merge(time,handleData,how='left',left_on='time',right_index=True)\n",
    "        result.set_index('time',inplace = True)\n",
    "        result = result.interpolate()\n",
    "    else:\n",
    "        result = handleData\n",
    "\n",
    "    return result\n",
    "\n",
    "# def recoverWea(data):\n",
    "    \n",
    "    \n",
    "def predict():\n",
    "    routes = {}\n",
    "    links = {}\n",
    "    with open(table3,'r') as fr:\n",
    "        lines = csv.reader(fr)\n",
    "        for line in lines:\n",
    "            if lines.line_num == 1:\n",
    "                continue\n",
    "            # length,lane\n",
    "            links[line[0]] = [int(line[1]),int(line[3])]\n",
    "\n",
    "    with open(table4,'r') as fr:\n",
    "        lines = csv.reader(fr)\n",
    "        for line in lines:\n",
    "            if lines.line_num == 1:\n",
    "                continue\n",
    "            if line[0] not in routes.keys():\n",
    "                routes[line[0]] = {}\n",
    "            routes[line[0]][line[1]] = line[2].split(',')\n",
    "            \n",
    "    print '==========================='\n",
    "    print 'preparation completes'\n",
    "    \n",
    "    trainData = getData(splitDataPath)\n",
    "    testData = getData(testDataPath)\n",
    "    trainDataByLink = splitDataByLane(trainData,routes)\n",
    "    testDataByLink = splitDataByLane(testData,routes)\n",
    "    predictLaneVelo = {}\n",
    "    \n",
    "    \n",
    "    print '==========================='\n",
    "    print 'prepate with lane'\n",
    "    if not os.path.exists(arimaPicturePath):\n",
    "        os.makedirs(arimaPicturePath)\n",
    "    \n",
    "    for lane in trainDataByLink.keys():\n",
    "        print '==========================='\n",
    "        print lane\n",
    "        data = trainDataByLink[lane]\n",
    "        testData = handleWeaInflu(testDataByLink[lane],True)\n",
    "        handleData = handleWeaInflu(data)\n",
    "        handleData.plot()\n",
    "        result = []\n",
    "        plt.savefig(arimaPicturePath+lane+'_trace_picture.png')\n",
    "        test_span = 6\n",
    "        size = 14\n",
    "        i = 0\n",
    "        while(i<size):\n",
    "            predict = run_aram(handleData,10,10,18)\n",
    "            handleData = pd.concat([handleData,predict,testData[i*6:(i+1)*6]])\n",
    "            print handleData\n",
    "            if i%2!=0:\n",
    "                result.append(predict[0:6])\n",
    "                predict = run_arm(handleData,10,10,24)\n",
    "                handleData = pd.concat([handleData,predict])\n",
    "                result.append(predict[0:6])\n",
    "            i = i+1\n",
    "        temp = pd.concat(result)\n",
    "        predictLaneVelo[lane] = temp\n",
    "    \n",
    "    for lane in links.keys():\n",
    "        # recover weather\n",
    "        predictLaneVelo[lane]['time'] = float(links[lane][0])/predictLaneVelo[lane]['travel_velocity']\n",
    "    \n",
    "    result = []\n",
    "    for intersection in routes.keys():\n",
    "        for tollgate in routes[intersection].keys():\n",
    "            temp = predictLaneVelo[lane].copy()\n",
    "            temp['intersection'] = intersection\n",
    "            temp['tollgate'] = tollgate\n",
    "            temp.drop(['time','travel_velocity'],axis = 1,inplace = True)\n",
    "            temp['predict_time'] = temp.index\n",
    "            temp['predict_name'] = 0\n",
    "            for lane in routes[intersection][tollgate]:\n",
    "                temp['predict_time'] = temp['predict_time']+predictLaneVelo[lane]['time']\n",
    "            result.append(temp)\n",
    "    \n",
    "    \n",
    "    result = pd.concat(result)\n",
    "    result.to_csv(arimaPicturePath+'result.csv')\n",
    "    \n",
    "        \n",
    "\n",
    "def test_stationarity(timeseries):\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    print dftest\n",
    "    return dftest[1]\n",
    "\n",
    "def bestDiff(df, maxdiff = 8):\n",
    "    p_set = {}\n",
    "    for i in range(0, maxdiff):\n",
    "        temp = df.copy() #每次循环前，重置\n",
    "        if i == 0:\n",
    "            temp['diff'] = temp[temp.columns[1]]\n",
    "        else:\n",
    "            temp['diff'] = temp[temp.columns[1]].diff(i)\n",
    "            temp = temp.drop(temp.iloc[:i].index) #差分后，前几行的数据会变成nan，所以删掉\n",
    "        pvalue = test_stationarity(temp['diff'])\n",
    "        p_set[i] = pvalue\n",
    "        p_df = pd.DataFrame.from_dict(p_set, orient=\"index\")\n",
    "        p_df.columns = ['p_value']\n",
    "    i = 0\n",
    "    while i < len(p_df):\n",
    "        if p_df['p_value'][i]<0.01:\n",
    "            bestdiff = i\n",
    "            break\n",
    "        i += 1\n",
    "    return bestdiff\n",
    "\n",
    "def produce_diffed_timeseries(df, diffn):\n",
    "    if diffn != 0:\n",
    "        df['diff'] = df[df.columns[1]].apply(lambda x:float(x)).diff(diffn)\n",
    "    else:\n",
    "        df['diff'] = df[df.columns[1]].apply(lambda x:float(x))\n",
    "    df.dropna(inplace=True) #差分之后的nan去掉\n",
    "    return df\n",
    "\n",
    "def choose_order(ts, maxar, maxma):\n",
    "    print 'choose order'\n",
    "    order = sm.tsa.arma_order_select_ic(ts, maxar, maxma, ic=['aic', 'bic', 'hqic'])\n",
    "    print 'finish'\n",
    "    return order.bic_min_order\n",
    "\n",
    "def predict_recover(ts, df, diffn):\n",
    "    if diffn != 0:\n",
    "        ts.iloc[0] = ts.iloc[0]+df['log'][-diffn]\n",
    "        ts = ts.cumsum()\n",
    "    ts = np.exp(ts)\n",
    "#    ts.dropna(inplace=True)\n",
    "    print('还原完成')\n",
    "    return ts\n",
    "\n",
    "\n",
    "def run_aram(df, maxar, maxma, test_size = 14):\n",
    "    \n",
    "    train = df.dropna()\n",
    "    train['log'] = np.log(train[train.columns[0]])\n",
    "    diffn = 0\n",
    "    if test_stationarity(train[train.columns[1]]) < 0.01:\n",
    "        train['diff'] = train['log']\n",
    "        print('平稳，不需要差分')\n",
    "    else:\n",
    "        diffn = best_diff(train, maxdiff = 8)\n",
    "        train = produce_diffed_timeseries(train, diffn)\n",
    "        print('差分阶数为'+str(diffn)+'，已完成差分')\n",
    "    print('开始进行ARMA拟合')\n",
    "    print train[train.columns[2]].values\n",
    "    order = choose_order(train[train.columns[2]].values, maxar, maxma)\n",
    "    print('模型的阶数为：'+str(order))\n",
    "    _ar = order[0]\n",
    "    _ma = order[1]\n",
    "    model = pf.ARIMA(data=train, ar=_ar, ma=_ma, target='diff', family=pf.Normal())\n",
    "    model.fit(\"MLE\")\n",
    "    test_predict = model.predict(int(test_size))\n",
    "    test_predict = predict_recover(test_predict, train, diffn)\n",
    "    return test_predict\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "preparation completes\n",
      "===========================\n",
      "weather data is\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5652 entries, 0 to 5651\n",
      "Data columns (total 8 columns):\n",
      "time              5652 non-null object\n",
      "pressure          5563 non-null float64\n",
      "sea_pressure      5563 non-null float64\n",
      "wind_direction    5563 non-null float64\n",
      "wind_speed        5563 non-null float64\n",
      "temperature       5563 non-null float64\n",
      "rel_humidity      5563 non-null float64\n",
      "precipitation     5563 non-null float64\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 353.3+ KB\n",
      "None\n",
      "===========================\n",
      "begain to split\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 617802 entries, 2016-07-19 00:00:00 to 2016-10-17 23:40:00\n",
      "Data columns (total 9 columns):\n",
      "lane_id            617802 non-null object\n",
      "travel_velocity    617802 non-null float64\n",
      "pressure           606847 non-null float64\n",
      "sea_pressure       606847 non-null float64\n",
      "wind_direction     606847 non-null float64\n",
      "wind_speed         606847 non-null float64\n",
      "temperature        606847 non-null float64\n",
      "rel_humidity       606847 non-null float64\n",
      "precipitation      606847 non-null float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 47.1+ MB\n",
      "None\n",
      "===========================\n",
      "weather data is\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 8 columns):\n",
      "time              84 non-null object\n",
      "pressure          84 non-null float64\n",
      "sea_pressure      84 non-null float64\n",
      "wind_direction    84 non-null float64\n",
      "wind_speed        84 non-null float64\n",
      "temperature       84 non-null float64\n",
      "rel_humidity      84 non-null float64\n",
      "precipitation     84 non-null float64\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 5.3+ KB\n",
      "None\n",
      "===========================\n",
      "begain to split\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 16872 entries, 2016-10-18 06:00:00 to 2016-10-24 17:00:00\n",
      "Data columns (total 9 columns):\n",
      "lane_id            16872 non-null object\n",
      "travel_velocity    16872 non-null float64\n",
      "pressure           16790 non-null float64\n",
      "sea_pressure       16790 non-null float64\n",
      "wind_direction     16790 non-null float64\n",
      "wind_speed         16790 non-null float64\n",
      "temperature        16790 non-null float64\n",
      "rel_humidity       16790 non-null float64\n",
      "precipitation      16790 non-null float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "===========================\n",
      "prepate with lane\n",
      "===========================\n",
      "115\n",
      "(-12.312285700884608, 7.0475537350231081e-23, 39, 12932, {'5%': -2.8617635251812796, '1%': -3.4308557685195935, '10%': -2.5668889775141599}, 8910.9521689984213)\n",
      "平稳，不需要差分\n",
      "开始进行ARMA拟合\n",
      "[ 2.27766456  2.35218598  2.42153704 ...,  2.68769797  2.38434267\n",
      "  2.38434267]\n",
      "choose order\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
